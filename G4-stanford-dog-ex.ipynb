{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://ckdals29672.tistory.com/m/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import os\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터셋 불러오기\n",
    "- stanford_dogs 데이터셋 사용\n",
    "- stanford_dogs 데이터셋에는 120개 견종의 이미지가 포함\n",
    "- 총 20,580장의 이미지에서 12,000장은 학습셋, 나머지 8,580장은 평가용 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/Users/yoonjeongyang/Desktop/AI-exer/augmentation/stanford_dogs/Images/\"\n",
    "dogs_name_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 각 이미지 디렉토리 이름 변경 ###########################################################\n",
    "# for folder in dogs_name_list:\n",
    "#     dir_name = folder\n",
    "#     rename = folder.split(\"-\")[1]\n",
    "#     os.rename(path+dir_name, path+rename)\n",
    "# dogs_name_list = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 이미지 제너레이터 생성 #################################################################\n",
    "datagen = ImageDataGenerator(\n",
    "    zca_epsilon=1e-06,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.2,\n",
    "    fill_mode='nearest',\n",
    "    horizontal_flip=True,\n",
    "    dtype='float32',\n",
    "    validation_split=0.1,# set validation split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (224,224)\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train 이미지 제너레이터 생성 ##############################################################\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=img_size,\n",
    "    batch_size= batch_size,\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Valid 이미지 제너레이터 생성 #############################################################\n",
    "valid_generator = datagen.flow_from_directory(\n",
    "    directory=path,\n",
    "    target_size=img_size,\n",
    "    batch_size= batch_size,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = next(iter(train_generator))\n",
    "print(train_img[0].shape)\n",
    "print(train_img[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dogs_name_dict = {}\n",
    "for key, name in enumerate(train_generator.class_indices):\n",
    "    dogs_name_dict[key] = name\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(8):\n",
    "    plt.subplot(2,4,i+1)\n",
    "    num = np.random.randint(0,batch_size)\n",
    "    plt.imshow((train_img[0][num]).astype(\"uint8\"))\n",
    "    plt.title(dogs_name_dict[np.argmax((train_img[1][num]))])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 데이터 전처리 ################################################################################\n",
    "## Batch크기 데이터셋의 값 분포(히스토그램)\n",
    "\n",
    "plt.hist(x=train_img[0].reshape(-1,),bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한개 이미지의 값 분포(히스토그램)\n",
    "num = np.random.randint(0,batch_size)\n",
    "\n",
    "plt.figure(figsize=(8,3))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow((train_img[0][num]).astype(\"uint8\"))\n",
    "plt.title(dogs_name_dict[np.argmax((train_img[1][num]))])\n",
    "plt.axis('off')\n",
    "plt.subplot(1,2,2)\n",
    "sns.histplot(x=train_img[0][num].reshape(-1,),bins=50,kde=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 한개 이미지의 값 -1~1로 정규화\n",
    "img_normalize = (train_img[0][num] / 127.5) -1\n",
    "\n",
    "plt.figure(figsize=(10,2))\n",
    "for i in range(3):\n",
    "    plt.subplot(1,6,2*i+1)\n",
    "    plt.imshow(img_normalize[:,:,i])\n",
    "    plt.title(dogs_name_dict[np.argmax((train_img[1][num]))]+'filter'+str(i))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,6,2*i+2)\n",
    "    sns.histplot(x=img_normalize[:,:,i].reshape(-1,),bins=50,kde=True)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 정규화된 서로 다른 이미지 그래프 비교 #######################################################\n",
    "## 이미지가 밝을 수록 골고루 퍼져있고 반면 이미지가 어두울 수록 -1.0쪽으로 쏠림\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i in range(2):\n",
    "    num = np.random.randint(0,batch_size)\n",
    "    img_normalize = (train_img[0][num] / 127.5) -1\n",
    "    \n",
    "    plt.subplot(2,2,2*i+1)\n",
    "    plt.imshow(img_normalize[:,:,2], vmax=1)\n",
    "    plt.title(dogs_name_dict[np.argmax((train_img[1][num]))])\n",
    "    plt.colorbar()\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(2,2,2*i+2)\n",
    "    sns.histplot(x=img_normalize[:,:,2].reshape(-1,),bins=50,kde=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdvWE8w%2FbtrFvrDVlfS%2FpVnkpzKqF9oLMkFMW7ewQ0%2Fimg.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 모델 만들기 ################################################################################\n",
    "## inception_256 Model\n",
    "def inception_256(input_image):\n",
    "    conv1 = layers.Conv2D(64,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    \n",
    "    conv3 = layers.Conv2D(96,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    conv3 = layers.Conv2D(128,(3,3),kernel_initializer=\"he_normal\",padding=\"same\")(conv3)\n",
    "    \n",
    "    conv5 = layers.Conv2D(16,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    conv5 = layers.Conv2D(32,(5,5),kernel_initializer=\"he_normal\",padding=\"same\")(conv5)\n",
    "\n",
    "    convMax = layers.MaxPool2D(pool_size=(3,3),strides=1,padding=\"same\")(input_image)\n",
    "    convMax = layers.Conv2D(32,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(convMax)\n",
    "\n",
    "    convCat = layers.Concatenate(axis=3)([conv1,conv3,conv5,convMax])\n",
    "    return convCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inception_384 Model\n",
    "def inception_384(input_image):\n",
    "    conv1 = layers.Conv2D(96,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    \n",
    "    conv3 = layers.Conv2D(96,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    conv3 = layers.Conv2D(192,(3,3),kernel_initializer=\"he_normal\",padding=\"same\")(conv3)\n",
    "    \n",
    "    conv5 = layers.Conv2D(24,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    conv5 = layers.Conv2D(48,(5,5),kernel_initializer=\"he_normal\",padding=\"same\")(conv5)\n",
    "\n",
    "    convMax = layers.MaxPool2D(pool_size=(3,3),strides=1,padding=\"same\")(input_image)\n",
    "    convMax = layers.Conv2D(48,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(convMax)\n",
    "\n",
    "    convCat = layers.Concatenate(axis=3)([conv1,conv3,conv5,convMax])\n",
    "    return convCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Inception\n",
    "def inception(input_image):\n",
    "    conv1 = layers.Conv2D(128,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    \n",
    "    conv3 = layers.Conv2D(128,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    conv3 = layers.Conv2D(256,(3,3),kernel_initializer=\"he_normal\",padding=\"same\")(conv3)\n",
    "    \n",
    "    conv5 = layers.Conv2D(24,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    conv5 = layers.Conv2D(64,(5,5),kernel_initializer=\"he_normal\",padding=\"same\")(conv5)\n",
    "\n",
    "    convMax = layers.MaxPool2D(pool_size=(3,3),strides=1,padding=\"same\")(input_image)\n",
    "    convMax = layers.Conv2D(64,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(convMax)\n",
    "\n",
    "    convCat = layers.Concatenate(axis=3)([conv1,conv3,conv5,convMax])\n",
    "    return convCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## inception_720\n",
    "def inception_720(input_image):\n",
    "    conv1 = layers.Conv2D(180,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    \n",
    "    conv3 = layers.Conv2D(180,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    conv3 = layers.Conv2D(360,(3,3),kernel_initializer=\"he_normal\",padding=\"same\")(conv3)\n",
    "    \n",
    "    conv5 = layers.Conv2D(45,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(input_image)\n",
    "    conv5 = layers.Conv2D(90,(5,5),kernel_initializer=\"he_normal\",padding=\"same\")(conv5)\n",
    "\n",
    "    convMax = layers.MaxPool2D(pool_size=(3,3),strides=1,padding=\"same\")(input_image)\n",
    "    convMax = layers.Conv2D(90,(1,1),kernel_initializer=\"he_normal\",padding=\"same\")(convMax)\n",
    "\n",
    "    convCat = layers.Concatenate(axis=3)([conv1,conv3,conv5,convMax])\n",
    "    return convCat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = layers.Input(shape=(224,224,3))\n",
    "\n",
    "# Feature Extraction\n",
    "layer0 = layers.Rescaling(scale=1./127.5, offset=-1)(input_image)\n",
    "\n",
    "layer1 = layers.Conv2D(20,(3,3),kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=regularizers.l2())(layer0)\n",
    "layer1 = layers.BatchNormalization()(layer1)  \n",
    "layer1 = layers.Activation('relu')(layer1)                \n",
    "layer1 = layers.MaxPool2D((2,2))(layer1)\n",
    "\n",
    "\n",
    "layer2 = layers.Conv2D(64,(2,2),kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=regularizers.l2())(layer1)\n",
    "layer2 = layers.BatchNormalization()(layer2)  \n",
    "layer2 = layers.Activation('relu')(layer2)\n",
    "layer2 = layers.MaxPool2D((2,2))(layer2)\n",
    "\n",
    "layer3 = layers.Conv2D(192,(3,3),kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=regularizers.l2())(layer2)\n",
    "layer3 = layers.BatchNormalization()(layer3)  \n",
    "layer3 = layers.Activation('relu')(layer3)\n",
    "layer3 = layers.MaxPool2D((2,2))(layer3)\n",
    "\n",
    "\n",
    "# Inception Network\n",
    "layer4 = inception_256(layer3)\n",
    "layer4 = layers.BatchNormalization()(layer4)\n",
    "layer4 = layers.Activation('relu')(layer4)\n",
    "\n",
    "layer5 = inception_384(layer4)\n",
    "layer5 = layers.BatchNormalization()(layer5)\n",
    "layer5 = layers.Activation('relu')(layer5)\n",
    "\n",
    "layer6 = inception(layer5)\n",
    "layer6 = layers.BatchNormalization()(layer6)\n",
    "layer7 = layers.Activation('relu')(layer6)\n",
    "\n",
    "layer8 = inception(layer7)\n",
    "layer8 = layers.BatchNormalization()(layer8)\n",
    "layer8 = layers.Activation('relu')(layer8)\n",
    "\n",
    "layer9 = inception(layer8)\n",
    "layer9 = layers.BatchNormalization()(layer9)\n",
    "layer9 = layers.Activation('relu')(layer9)\n",
    "layer9 = layers.MaxPool2D((2,2))(layer9)\n",
    "\n",
    "\n",
    "layer10 = inception_720(layer9)\n",
    "layer10 = layers.BatchNormalization()(layer10)\n",
    "layer10 = layers.Activation('relu')(layer10)\n",
    "\n",
    "layer11 = inception_720(layer10)\n",
    "layer11 = layers.BatchNormalization()(layer11)\n",
    "layer11 = layers.Activation('relu')(layer11)\n",
    "\n",
    "layer12 = inception_720(layer11)\n",
    "layer12 = layers.BatchNormalization()(layer12)\n",
    "layer12 = layers.Activation('relu')(layer12)\n",
    "layer13 = layers.GlobalAveragePooling2D()(layer12)\n",
    "\n",
    "\n",
    "# Fully Connected Network\n",
    "layer14 = layers.Dense(512,kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=regularizers.l2())(layer13)\n",
    "layer14 = layers.BatchNormalization()(layer14)\n",
    "layer14 = layers.Activation('relu')(layer14)\n",
    "layer14 = layers.Dropout(0.3)(layer14)\n",
    "\n",
    "layer15 = layers.Dense(256,kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=regularizers.l2())(layer14)\n",
    "layer15 = layers.BatchNormalization()(layer15)\n",
    "layer15 = layers.Activation('relu')(layer15)\n",
    "layer15 = layers.Dropout(0.2)(layer15)\n",
    "\n",
    "layer16 = layers.Dense(256,kernel_initializer='he_normal',\n",
    "                       kernel_regularizer=regularizers.l2())(layer15)\n",
    "layer16 = layers.BatchNormalization()(layer16)\n",
    "layer16 = layers.Activation('relu')(layer16)\n",
    "layer16 = layers.Dropout(0.1)(layer16)\n",
    "\n",
    "layer17 = layers.Dense(120,activation='softmax')(layer16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs = input_image,outputs=layer17)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.utils.plot_model(model,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### GPU 확인 ###########################################################################\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 학습 설정 ######################################################################\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 7. Model Checkpoint Callback ############################################################################\n",
    "checkpt_dir = '/Users/yoonjeongyang/Desktop/AI-exer/augmentation/networks/'\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpt_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 save_freq='epoch',\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 학습 실행 #####################################################################\n",
    "\n",
    "history = model.fit(train_generator,epochs=200,validation_data=valid_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 학습 결과 그래프로 표현 ###########################################################\n",
    "plt.plot(hist['loss'],label='loss')\n",
    "plt.plot(hist['val_loss'],label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist['accuracy'],label='accuracy')\n",
    "plt.plot(hist['val_accuracy'],label='val_accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 임의 배치 valid 데이터로 평가 및 예측 확인 #############################################\n",
    "valid_img = next(iter(valid_generator))\n",
    "model.evaluate(valid_img[0],valid_img[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.random.randint(0,batch_size)\n",
    "plt.imshow(valid_img[0][num].astype('uint8'))\n",
    "plt.title(dogs_name_dict[np.argmax(valid_img[1][num])])\n",
    "plt.show()\n",
    "\n",
    "y_pred = model(np.expand_dims(valid_img[0][num],axis=0)).numpy()[0]\n",
    "names = np.argsort(y_pred)[::-1][:4]\n",
    "\n",
    "for name in names:\n",
    "    print(y_pred[name],\":\",dogs_name_dict[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.random.randint(0,batch_size)\n",
    "plt.imshow(valid_img[0][num].astype('uint8'))\n",
    "plt.title(dogs_name_dict[np.argmax(valid_img[1][num])])\n",
    "plt.show()\n",
    "\n",
    "y_pred = model(np.expand_dims(valid_img[0][num],axis=0)).numpy()[0]\n",
    "names = np.argsort(y_pred)[::-1][:4]\n",
    "\n",
    "for name in names:\n",
    "    print(y_pred[name],\":\",dogs_name_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = np.random.randint(0,batch_size)\n",
    "plt.imshow(valid_img[0][num].astype('uint8'))\n",
    "plt.title(dogs_name_dict[np.argmax(valid_img[1][num])])\n",
    "plt.show()\n",
    "\n",
    "y_pred = model(np.expand_dims(valid_img[0][num],axis=0)).numpy()[0]\n",
    "names = np.argsort(y_pred)[::-1][:4]\n",
    "\n",
    "for name in names:\n",
    "    print(y_pred[name],\":\",dogs_name_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### pomeranian(포메라니안) Test 이미지로 오류 분석 하기 #######################################\n",
    "## 흰색 포메라니안 이미지 예측\n",
    "pomeranian_img_path = '/Users/yoonjeongyang/Desktop/AI-exer/augmentation/stanford_dogs/test_images/white.jpg'\n",
    "pomeranian_img =cv2.imread(pomeranian_img_path)\n",
    "pomeranian_img = cv2.cvtColor(pomeranian_img,cv2.COLOR_BGR2RGB)\n",
    "pomeranian_img = cv2.resize(pomeranian_img,(224,224))\n",
    "plt.imshow(pomeranian_img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "y_pred = model(np.expand_dims(pomeranian_img,axis=0)).numpy()[0]\n",
    "names = np.argsort(y_pred)[::-1][:4]\n",
    "\n",
    "for name in names:\n",
    "    print(y_pred[name],\":\",dogs_name_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 갈색 포메라니안 이미지 예측 \n",
    "pomeranian_img_path = '/Users/yoonjeongyang/Desktop/AI-exer/augmentation/stanford_dogs/test_images/brown.jpg'\n",
    "pomeranian_img =cv2.imread(pomeranian_img_path)\n",
    "pomeranian_img = cv2.cvtColor(pomeranian_img,cv2.COLOR_BGR2RGB)\n",
    "pomeranian_img = cv2.resize(pomeranian_img,(224,224))\n",
    "plt.imshow(pomeranian_img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "y_pred = model(np.expand_dims(pomeranian_img,axis=0)).numpy()[0]\n",
    "names = np.argsort(y_pred)[::-1][:4]\n",
    "\n",
    "for name in names:\n",
    "    print(y_pred[name],\":\",dogs_name_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 포메라니안 학습 이미지 확인하기 ############################################################\n",
    "pomeranian_path = '/Users/yoonjeongyang/Desktop/AI-exer/augmentation/stanford_dogs/Images/Pomeranian/'\n",
    "pomeranian_list = os.listdir(pomeranian_path)\n",
    "\n",
    "plt.figure(figsize=(30,20))\n",
    "np.random.shuffle(pomeranian_list) # 이미지들의 순서를 무작위로 섞어 골고루 이미지를 뽑아 올 수 있도록 한다.\n",
    "for i in range(60):\n",
    "    plt.subplot(6,10,i+1)\n",
    "    img =cv2.imread(pomeranian_path+pomeranian_list[i])\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img,(100,100))\n",
    "    plt.imshow(img)\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Dandie Terrier 이미지의 클래스 활성화 맵 분석 ##################################################\n",
    "pomeranian_img_path = '/Users/yoonjeongyang/Desktop/AI-exer/augmentation/stanford_dogs/test_images/dandie_terrier.jpg'\n",
    "pomeranian_img =cv2.imread(pomeranian_img_path)\n",
    "pomeranian_img = cv2.cvtColor(pomeranian_img,cv2.COLOR_BGR2RGB)\n",
    "pomeranian_img = cv2.resize(pomeranian_img,(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pomeranian_img.copy()\n",
    "img = np.expand_dims(img,[0])\n",
    "img = tf.Variable(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(img.numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_conv_layer = model.get_layer('activation_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_input_model = models.Model(model.input, temp_conv_layer.input)\n",
    "temp_output_model = models.Model(temp_conv_layer.output, model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    temp_input_model_ouput = temp_input_model(img)\n",
    "    temp_input_model_ouput = tf.Variable(temp_input_model_ouput)\n",
    "    temp_output_model_output = temp_output_model(temp_input_model_ouput)[0,np.argmax(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = tape.gradient(temp_output_model_output,temp_input_model_ouput)\n",
    "\n",
    "pooled_grads = tf.reduce_mean(grads,axis=(0,1,2))\n",
    "\n",
    "pooled_grads_value = pooled_grads.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_output_value = temp_input_model_ouput[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(512):\n",
    "    conv_layer_output_value[:,:,i] *= pooled_grads[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = np.mean(conv_layer_output_value,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = cv2.resize(heatmap, (pomeranian_img.shape[1],pomeranian_img.shape[0]))\n",
    "heatmap = np.abs(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_rgb = (heatmap - np.min(heatmap))/(np.max(heatmap) - np.min(heatmap))\n",
    "# minmax 정규화 -> 0~1로 정규화\n",
    "heatmap_rgb = np.uint8(heatmap_rgb*255) # RGB포맷(0~255)으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = cv2.applyColorMap(heatmap_rgb, cv2.COLORMAP_JET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "superimposed_img = heatmap*0.4 + pomeranian_img\n",
    "superimposed_img = np.minimum(255,superimposed_img).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.minimum(255,superimposed_img).astype('uint8'))\n",
    "plt.title(\"Dandie_terrier\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.argsort(preds)[::-1][:4]\n",
    "\n",
    "for name in names:\n",
    "    print(preds[name],\":\",dogs_name_dict[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Top3 클래스 정확도 확인 #####################################################################\n",
    "y_pred_top3 = np.argsort(model(valid_img[0]))[:,::-1][:,:3]\n",
    "y = np.argmax(valid_img[1],axis=1)\n",
    "\n",
    "accuracy = 0\n",
    "for i in range(len(y)):\n",
    "    if(np.sum(y_pred_top3[i] == y[i])):\n",
    "        accuracy +=1\n",
    "\n",
    "accuracy /=240\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02aaae3c9b50b62c88d0cc652c4ef3b1b4bf05515e9d7a066ea77f7c79246682"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
